{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# ðŸŽ¬ AI Storyboard Weaver for Filmmakers 2.0\n",
    "\n",
    "**Capstone Project: Gen AI Intensive Course 2025Q1**  \n",
    "*Author: Aya Nabil*  \n",
    "*Date: April 09, 2025*  \n",
    "*Version: 2.0 (Enhanced with Agents & RAG)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Enhanced Capstone Goal & GenAI Capabilities\n",
    "\n",
    "This enhanced version implements a professional Automated Storyboard Weaver with:\n",
    "\n",
    "âœ… **Agent-Based Function Calling System**  \n",
    "- Proper orchestration of generation tasks  \n",
    "- Specialized functions for each operation  \n",
    "- Error handling and validation  \n",
    "\n",
    "âœ… **True RAG Pipeline**  \n",
    "- Sentence Transformers for embeddings  \n",
    "- Cosine similarity for plot retrieval  \n",
    "- Persistent knowledge base  \n",
    "\n",
    "âœ… **Improved UI/UX**  \n",
    "- Progress indicators  \n",
    "- Enhanced visualizations  \n",
    "- Better error handling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Technical Architecture\n",
    "    \n",
    "```mermaid\n",
    "graph TD\n",
    "    A[User Input] --> B[StoryboardAgent]\n",
    "    B --> C[Generate Storyboard]\n",
    "    B --> D[Analyze Mood]\n",
    "    B --> E[Retrieve Similar Plots]\n",
    "    C --> F[Gemini API]\n",
    "    E --> G[Knowledge Base]\n",
    "    G --> H[Embeddings Store]\n",
    "    F --> I[Visualization]\n",
    "    D --> I\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cm  \u001b[38;5;66;03m# For color mapping in visualizations\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# RAG components for retrieval-augmented generation\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer  \u001b[38;5;66;03m# For generating embeddings of text (plots)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity  \u001b[38;5;66;03m# For calculating similarity between embeddings\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Suppress warnings to keep the notebook output clean\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\__init__.py:14\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     CrossEncoder,\n\u001b[0;32m     16\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     17\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfit_mixin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FitMixin\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData, generate_model_card\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     34\u001b[0m     cross_encoder_init_args_decorator,\n\u001b[0;32m     35\u001b[0m     cross_encoder_predict_rank_args_decorator,\n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\fit_mixin.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\datasets\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\datasets\\ParallelSentencesDataset.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_npu_available\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimilarity_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityFunction\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __MODEL_HUB_ORGANIZATION__, __version__\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\model_card.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeCarbonCallback\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_markdown_table\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerControl, TrainerState\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1953\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "# Standard library imports for basic functionality\n",
    "import json  # For handling JSON data (e.g., API responses, knowledge base)\n",
    "import re  # For regular expressions to parse API output\n",
    "import warnings  # To suppress unnecessary warnings for cleaner output\n",
    "from typing import Dict, List, Optional, Tuple  # For type hints to improve code readability\n",
    "import os  # For file system operations (e.g., checking if knowledge base exists)\n",
    "from pathlib import Path  # For handling file paths in a cross-platform way\n",
    "from datetime import datetime  # For timestamping knowledge base entries\n",
    "\n",
    "# Third-party imports for external functionality\n",
    "import requests  # For making HTTP requests to the Gemini API and Wikipedia\n",
    "from bs4 import BeautifulSoup  # For parsing HTML content from Wikipedia\n",
    "import matplotlib.pyplot as plt  # For creating visualizations (e.g., mood distribution chart)\n",
    "import numpy as np  # For numerical operations (e.g., array handling in RAG)\n",
    "from IPython.display import display, Markdown, HTML  # For rendering markdown and HTML in Jupyter\n",
    "from ipywidgets import widgets, Layout  # For creating interactive UI elements (e.g., text input, buttons)\n",
    "import matplotlib.colors as mcolors  # For accessing predefined color sets for visualizations\n",
    "from matplotlib import cm  # For color mapping in visualizations\n",
    "\n",
    "# RAG components for retrieval-augmented generation\n",
    "from sentence_transformers import SentenceTransformer  # For generating embeddings of text (plots)\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # For calculating similarity between embeddings\n",
    "\n",
    "# Suppress warnings to keep the notebook output clean\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration dictionary with enhanced settings for the application\n",
    "CONFIG = {\n",
    "    \"api_url\": \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent\",  # URL for Gemini API with updated model\n",
    "    \"max_scenes\": 5,  # Maximum number of scenes allowed in a storyboard\n",
    "    \"moods\": [\"tense\", \"joyful\", \"romantic\", \"suspenseful\", \"chaotic\", \"dark\", \"hopeful\"],  # List of possible moods for scenes\n",
    "    \"context_length\": 300,  # Maximum length of context text fetched from Wikipedia\n",
    "    \"colors\": list(mcolors.TABLEAU_COLORS.values()),  # Colors for visualizations (e.g., mood chart)\n",
    "    \"max_retries\": 3,  # Maximum number of retries for API calls\n",
    "    \"rag_threshold\": 0.7,  # Similarity threshold for RAG retrieval (cosine similarity)\n",
    "    \"knowledge_base\": \"knowledge_base.json\",  # File path for persistent storage of RAG data\n",
    "    \"embedding_model\": \"all-MiniLM-L6-v2\",  # Sentence embedding model for RAG\n",
    "    \"default_genre\": \"drama\"  # Fallback genre if detection fails\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T20:32:41.287612Z",
     "iopub.status.busy": "2025-04-09T20:32:41.286397Z",
     "iopub.status.idle": "2025-04-09T20:32:41.296117Z",
     "shell.execute_reply": "2025-04-09T20:32:41.294027Z",
     "shell.execute_reply.started": "2025-04-09T20:32:41.287552Z"
    }
   },
   "source": [
    "## ðŸ” Secure API Configuration\n",
    "**Security Note:** API keys should never be hardcoded or exposed in notebooks.  \n",
    "This implementation uses:\n",
    "- IPython's Password widget to prevent key visibility\n",
    "- Environment variables for deployment\n",
    "- Secure handling throughout the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T20:33:13.991724Z",
     "iopub.status.busy": "2025-04-09T20:33:13.991363Z",
     "iopub.status.idle": "2025-04-09T20:33:14.002920Z",
     "shell.execute_reply": "2025-04-09T20:33:14.001566Z",
     "shell.execute_reply.started": "2025-04-09T20:33:13.991698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a password widget for secure API key input to avoid hardcoding sensitive information\n",
    "api_key = widgets.Password(\n",
    "    placeholder='Enter your Gemini API key',  # Placeholder text for the input field\n",
    "    description='API Key:',  # Label for the input field\n",
    "    layout=Layout(width='400px')  # Set the width of the widget for better UI\n",
    ")\n",
    "\n",
    "# Display the API key input widget in the notebook\n",
    "display(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– Storyboard Agent Architecture\n",
    "The agent system provides:\n",
    "- Orchestration of generation tasks\n",
    "- Specialized function calling\n",
    "- Error handling pipeline\n",
    "- Quality validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T20:34:27.376860Z",
     "iopub.status.busy": "2025-04-09T20:34:27.376501Z",
     "iopub.status.idle": "2025-04-09T20:34:27.403719Z",
     "shell.execute_reply": "2025-04-09T20:34:27.402187Z",
     "shell.execute_reply.started": "2025-04-09T20:34:27.376835Z"
    }
   },
   "outputs": [],
   "source": [
    "class StoryboardAgent:\n",
    "    \"\"\"Main agent class that manages the storyboard generation pipeline with RAG and API integration\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize the embedding model for RAG to convert plots into vector embeddings\n",
    "        try:\n",
    "            self.embedding_model = SentenceTransformer(CONFIG[\"embedding_model\"])  # Load the sentence transformer model\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not load embedding model: {e}\")  # Print error if model loading fails\n",
    "            self.embedding_model = None  # Set to None to disable RAG if model fails\n",
    "        \n",
    "        # Initialize the knowledge base for storing plots and storyboards\n",
    "        self._init_knowledge_base()\n",
    "        \n",
    "        # Register available functions for the agent to call dynamically\n",
    "        self.available_functions = {\n",
    "            \"generate_storyboard\": self.generate_storyboard,  # Function to generate a storyboard\n",
    "            \"analyze_mood\": self.analyze_mood,  # Function to analyze mood distribution\n",
    "            \"retrieve_similar_plots\": self.retrieve_similar_plots,  # Function to retrieve similar plots using RAG\n",
    "            \"save_storyboard\": self.save_storyboard,  # Function to save the storyboard to a file\n",
    "            \"validate_storyboard\": self.validate_storyboard  # Function to validate the storyboard structure\n",
    "        }\n",
    "\n",
    "    def _init_knowledge_base(self):\n",
    "        \"\"\"Initialize or load the RAG knowledge base from a JSON file\"\"\"\n",
    "        # Check if the knowledge base file exists\n",
    "        if not os.path.exists(CONFIG[\"knowledge_base\"]):\n",
    "            # If it doesn't exist, create a new JSON file with empty lists for scripts and plots\n",
    "            with open(CONFIG[\"knowledge_base\"], \"w\") as f:\n",
    "                json.dump({\"scripts\": [], \"plots\": []}, f)  # Initialize with empty structure\n",
    "\n",
    "    def execute_function(self, function_name: str, **kwargs):\n",
    "        \"\"\"Execute a registered function with error handling and progress feedback\"\"\"\n",
    "        # Check if the requested function exists in the registry\n",
    "        if function_name not in self.available_functions:\n",
    "            raise ValueError(f\"Unknown function: {function_name}\")  # Raise an error if function is not found\n",
    "        \n",
    "        try:\n",
    "            # Display a progress message to the user\n",
    "            display(Markdown(f\"ðŸ”§ Executing {function_name.replace('_', ' ')}...\"))\n",
    "            # Call the requested function with the provided arguments\n",
    "            return self.available_functions[function_name](**kwargs)\n",
    "        except Exception as e:\n",
    "            # Display an error message if the function fails\n",
    "            display(Markdown(f\"âš ï¸ **Error in {function_name}:** {str(e)}\"))\n",
    "            return None  # Return None to indicate failure\n",
    "\n",
    "    def generate_storyboard(self, plot: str, num_scenes: int = 3) -> Dict:\n",
    "        \"\"\"Generate a storyboard using the Gemini API with RAG context for enhanced generation\"\"\"\n",
    "        # Retrieve similar plots from the knowledge base to provide context\n",
    "        similar_plots = self.retrieve_similar_plots(plot)\n",
    "        # Format the similar plots into a string for inclusion in the prompt\n",
    "        rag_context = \"\\nSimilar plots:\\n\" + \"\\n\".join(\n",
    "            [f\"- {p['plot']}\" for p in similar_plots[:2]]) if similar_plots else \"\"\n",
    "        \n",
    "        # Build the prompt for the Gemini API with the plot and RAG context\n",
    "        prompt = self._build_prompt(plot, num_scenes, rag_context)\n",
    "        # Call the Gemini API to generate the storyboard\n",
    "        storyboard = self._call_generation_api(prompt)\n",
    "        \n",
    "        # If the storyboard was successfully generated, update the knowledge base\n",
    "        if storyboard:\n",
    "            self._update_knowledge_base(plot, storyboard)\n",
    "        return storyboard\n",
    "\n",
    "    def _build_prompt(self, plot: str, num_scenes: int, rag_context: str = \"\") -> str:\n",
    "    \"\"\"Construct the generation prompt with dynamic context for the Gemini API\"\"\"\n",
    "    # Detect the genre of the plot to fetch relevant context\n",
    "    genre = self.detect_genre(plot)\n",
    "    # Fetch genre-specific context from Wikipedia\n",
    "    wiki_context = self.fetch_wikipedia_film_data(genre)\n",
    "    # Fetch a sample script dialogue for the genre from the mock database\n",
    "    script_example = self.fetch_script_data(genre)\n",
    "    \n",
    "    # Get the visual style from the style_selector widget\n",
    "    visual_style = style_selector.value.lower()\n",
    "    \n",
    "    # Add instructions for documentary style if selected\n",
    "    style_instruction = \"\"\n",
    "    if visual_style == \"documentary\":\n",
    "        style_instruction = \"\"\"\n",
    "        - Use a documentary visual style: descriptions should feel realistic and observational, as if filmed by a camera crew documenting real events.\n",
    "        - Include elements like grainy footage, voiceover narration, location captions, or references to archival footage.\n",
    "        - Dialogue should be naturalistic, like interviews or recorded conversations, with historical context relevant to 1920s Paris (e.g., post-World War I, the art scene in Montmartre, the rise of jazz).\n",
    "        \"\"\"\n",
    "    \n",
    "    # Construct and return the prompt with all required components\n",
    "    return f\"\"\"Generate a film storyboard in JSON format based on: \"{plot}\"\n",
    "    Format Requirements:\n",
    "    - Strictly valid JSON output\n",
    "    - Title reflecting plot essence\n",
    "    - {num_scenes} scenes with:\n",
    "      â€¢ scene_number (1-{num_scenes})\n",
    "      â€¢ vivid description\n",
    "      â€¢ natural dialogue\n",
    "      â€¢ mood from: {CONFIG['moods']}\n",
    "    Visual Style: {visual_style}\n",
    "    {style_instruction}\n",
    "    Genre Context:\n",
    "    {wiki_context[:CONFIG['context_length']]}\n",
    "    {rag_context}\n",
    "    Example Dialogue:\n",
    "    {script_example}\n",
    "    Output:\"\"\"\n",
    "\n",
    "    def _call_generation_api(self, prompt: str) -> Dict:\n",
    "        \"\"\"Call the Gemini API to generate a storyboard with robust error handling\"\"\"\n",
    "        # Set the headers for the HTTP request (specifying JSON content type)\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        # Prepare the request payload with the prompt\n",
    "        data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
    "        \n",
    "        # Retry the API call up to the maximum number of retries\n",
    "        for attempt in range(CONFIG[\"max_retries\"]):\n",
    "            try:\n",
    "                # Construct the full API URL with the API key\n",
    "                url = f\"{CONFIG['api_url']}?key={api_key.value}\"\n",
    "                # Send a POST request to the Gemini API with a 30-second timeout\n",
    "                response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "                \n",
    "                # Check for specific HTTP errors\n",
    "                if response.status_code == 404:\n",
    "                    raise ValueError(\"Invalid API endpoint\")  # Endpoint not found\n",
    "                if response.status_code == 403:\n",
    "                    raise ValueError(\"API key rejected\")  # API key issue\n",
    "                \n",
    "                # Raise an exception for other HTTP errors\n",
    "                response.raise_for_status()\n",
    "                # Parse the JSON response from the API\n",
    "                result = response.json()\n",
    "                \n",
    "                # Validate the response format\n",
    "                if 'candidates' not in result:\n",
    "                    raise ValueError(\"Unexpected API response\")\n",
    "                \n",
    "                # Extract the generated text from the response\n",
    "                raw_output = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "                # Use regex to extract the JSON portion of the response\n",
    "                json_match = re.search(r'\\{.*\\}', raw_output, re.DOTALL)\n",
    "                \n",
    "                # If JSON is found, parse and validate it\n",
    "                if json_match:\n",
    "                    storyboard = json.loads(json_match.group(0))\n",
    "                    if self.validate_storyboard(storyboard):\n",
    "                        return storyboard  # Return the validated storyboard\n",
    "                        \n",
    "            except Exception as e:\n",
    "                # On the last attempt, if it fails, return a fallback storyboard\n",
    "                if attempt == CONFIG[\"max_retries\"] - 1:\n",
    "                    return self._create_fallback_storyboard(prompt.split('\"')[1] if '\"' in prompt else prompt)\n",
    "        \n",
    "        # If all retries fail, return a fallback storyboard\n",
    "        return self._create_fallback_storyboard(prompt.split('\"')[1] if '\"' in prompt else prompt)\n",
    "\n",
    "    def _create_fallback_storyboard(self, plot: str) -> Dict:\n",
    "        \"\"\"Create a minimal fallback storyboard when API generation fails\"\"\"\n",
    "        # Return a basic storyboard structure with placeholder scenes\n",
    "        return {\n",
    "            \"title\": f\"Untitled {plot}\",  # Simple title based on the plot\n",
    "            \"scenes\": [{\n",
    "                \"scene_number\": i+1,  # Scene number (1 to 3)\n",
    "                \"description\": f\"Scene {i+1} of {plot}\",  # Placeholder description\n",
    "                \"dialogue\": \"...\",  # Placeholder dialogue\n",
    "                \"mood\": \"neutral\"  # Default mood\n",
    "            } for i in range(3)]  # Default to 3 scenes\n",
    "        }\n",
    "\n",
    "    def detect_genre(self, plot: str) -> str:\n",
    "        \"\"\"Detect the film genre from plot keywords using a keyword mapping\"\"\"\n",
    "        # Convert the plot to lowercase for case-insensitive matching\n",
    "        plot_lower = plot.lower()\n",
    "        # Define a list of tuples mapping keywords to genres\n",
    "        genre_map = [\n",
    "            ([\"heist\", \"robbery\", \"steal\"], \"heist\"),\n",
    "            ([\"sci-fi\", \"futuristic\", \"space\", \"alien\"], \"sci-fi\"),\n",
    "            ([\"romance\", \"love\", \"relationship\"], \"romance\"),\n",
    "            ([\"thriller\", \"suspense\", \"mystery\"], \"thriller\")\n",
    "        ]\n",
    "        \n",
    "        # Check for keyword matches in the plot\n",
    "        for keywords, genre in genre_map:\n",
    "            if any(word in plot_lower for word in keywords):\n",
    "                return genre  # Return the matched genre\n",
    "        return CONFIG[\"default_genre\"]  # Default to 'drama' if no match\n",
    "\n",
    "    def fetch_wikipedia_film_data(self, genre: str) -> str:\n",
    "        \"\"\"Fetch film context from Wikipedia with error handling for genre-specific data\"\"\"\n",
    "        # Construct the Wikipedia URL for the genre\n",
    "        url = f\"https://en.wikipedia.org/wiki/{genre}_film\"\n",
    "        try:\n",
    "            # Send a GET request to Wikipedia with a 10-second timeout\n",
    "            response = requests.get(url, timeout=10)\n",
    "            # Raise an exception for HTTP errors\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse the HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # Find the main content div\n",
    "            content = soup.find('div', {'id': 'mw-content-text'})\n",
    "            # Extract the first 3 paragraphs\n",
    "            paragraphs = content.find_all('p')[:3] if content else []\n",
    "            \n",
    "            # Clean and join the paragraph text, limiting to context_length\n",
    "            return \" \".join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])[:CONFIG[\"context_length\"]]\n",
    "        except Exception as e:\n",
    "            # Display a warning if Wikipedia fetch fails\n",
    "            display(Markdown(f\"âš ï¸ **Wikipedia Unavailable:** Using generic context. (Error: {str(e)})\"))\n",
    "            return f\"Standard {genre} film context.\"  # Fallback context\n",
    "\n",
    "    def fetch_script_data(self, genre: str) -> str:\n",
    "        \"\"\"Fetch script snippets from a mock database based on the genre\"\"\"\n",
    "        # Define a mock database of script snippets for different genres\n",
    "        mock_scripts = {\n",
    "            \"heist\": \"INT. BANK VAULT - NIGHT\\nThe crew works silently until alarms blare.\\n\\\"We're made!\\\" shouts the leader.\",\n",
    "            \"sci-fi\": \"EXT. SPACE STATION\\nThe captain watches Earth from the viewport.\\n\\\"Initiate hyperdrive,\\\" she orders.\",\n",
    "            \"romance\": \"EXT. PARIS CAFE - DAY\\nThey share coffee as rain falls gently.\\n\\\"I've waited my whole life for this,\\\" he whispers.\",\n",
    "            \"thriller\": \"INT. ABANDONED HOUSE - NIGHT\\nA floorboard creaks. She holds her breath.\\n\\\"I know you're here,\\\" calls the killer.\"\n",
    "        }\n",
    "        # Return the script for the genre, or a default if not found\n",
    "        return mock_scripts.get(genre.lower(), \"Sample script dialogue.\")\n",
    "\n",
    "    def analyze_mood(self, storyboard: Dict) -> Dict:\n",
    "        \"\"\"Analyze the mood distribution in the storyboard for visualization\"\"\"\n",
    "        # Extract moods from each scene in the storyboard\n",
    "        moods = [scene.get(\"mood\", \"unknown\") for scene in storyboard.get(\"scenes\", [])]\n",
    "        # Count the frequency of each mood\n",
    "        return {mood: moods.count(mood) for mood in set(moods)} if moods else {}\n",
    "\n",
    "    def validate_storyboard(self, storyboard: Dict) -> bool:\n",
    "        \"\"\"Validate the structure of the generated storyboard to ensure it meets requirements\"\"\"\n",
    "        # Check if the storyboard has a title and scenes\n",
    "        if not isinstance(storyboard, dict) or \"title\" not in storyboard or \"scenes\" not in storyboard:\n",
    "            return False\n",
    "        # Check if scenes is a non-empty list\n",
    "        if not isinstance(storyboard[\"scenes\"], list) or not storyboard[\"scenes\"]:\n",
    "            return False\n",
    "        # Validate each scene's structure\n",
    "        for scene in storyboard[\"scenes\"]:\n",
    "            if not all(key in scene for key in [\"scene_number\", \"description\", \"dialogue\", \"mood\"]):\n",
    "                return False\n",
    "            if scene[\"mood\"] not in CONFIG[\"moods\"]:\n",
    "                return False\n",
    "        return True  # Return True if all checks pass\n",
    "\n",
    "    def save_storyboard(self, storyboard: Dict, filename: str) -> bool:\n",
    "        \"\"\"Save the storyboard to a JSON file and return success status\"\"\"\n",
    "        try:\n",
    "            # Write the storyboard to the specified file with proper formatting\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(storyboard, f, indent=2)\n",
    "            return True  # Return True if saving succeeds\n",
    "        except Exception as e:\n",
    "            # Display an error if saving fails\n",
    "            display(Markdown(f\"âš ï¸ **Error saving storyboard:** {str(e)}\"))\n",
    "            return False  # Return False if saving fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  RAG Implementation\n",
    "The Retrieval-Augmented Generation system provides contextual enhancement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T20:35:49.447579Z",
     "iopub.status.busy": "2025-04-09T20:35:49.447043Z",
     "iopub.status.idle": "2025-04-09T20:35:49.457748Z",
     "shell.execute_reply": "2025-04-09T20:35:49.456269Z",
     "shell.execute_reply.started": "2025-04-09T20:35:49.447542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extend the StoryboardAgent class with RAG methods\n",
    "def retrieve_similar_plots(self, plot: str, top_k: int = 3) -> List[Dict]:\n",
    "    \"\"\"Retrieve similar plots from the knowledge base using vector similarity\"\"\"\n",
    "    # Check if the embedding model is available\n",
    "    if not self.embedding_model:\n",
    "        return []  # Return empty list if embedding model failed to load\n",
    "    \n",
    "    # Load the knowledge base from the JSON file\n",
    "    with open(CONFIG[\"knowledge_base\"], \"r\") as f:\n",
    "        kb = json.load(f)\n",
    "    \n",
    "    # Check if there are any plots in the knowledge base\n",
    "    if not kb[\"plots\"]:\n",
    "        return []  # Return empty list if knowledge base is empty\n",
    "    \n",
    "    # Generate an embedding for the input plot\n",
    "    plot_embedding = self.embedding_model.encode(plot)\n",
    "    \n",
    "    # Calculate cosine similarities between the input plot and stored plots\n",
    "    similarities = []\n",
    "    for stored_plot in kb[\"plots\"]:\n",
    "        stored_embedding = np.array(stored_plot[\"embedding\"])\n",
    "        # Compute cosine similarity between the input and stored embeddings\n",
    "        similarity = cosine_similarity(\n",
    "            [plot_embedding],\n",
    "            [stored_embedding]\n",
    "        )[0][0]\n",
    "        similarities.append((stored_plot, similarity))\n",
    "    \n",
    "    # Sort by similarity and filter by threshold, returning the top_k matches\n",
    "    return [\n",
    "        plot for plot, sim in sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "        if sim > CONFIG[\"rag_threshold\"]\n",
    "    ][:top_k]\n",
    "\n",
    "def _update_knowledge_base(self, plot: str, storyboard: Dict):\n",
    "    \"\"\"Update the knowledge base with a new plot and its storyboard\"\"\"\n",
    "    try:\n",
    "        # Load the existing knowledge base\n",
    "        with open(CONFIG[\"knowledge_base\"], \"r\") as f:\n",
    "            kb = json.load(f)\n",
    "        \n",
    "        # Generate an embedding for the plot if the embedding model is available\n",
    "        if self.embedding_model:\n",
    "            plot_embedding = self.embedding_model.encode(plot).tolist()\n",
    "        else:\n",
    "            plot_embedding = []  # Use empty list if embedding model is unavailable\n",
    "        \n",
    "        # Add the new plot and storyboard to the knowledge base\n",
    "        kb[\"plots\"].append({\n",
    "            \"plot\": plot,  # Store the plot text\n",
    "            \"storyboard\": storyboard,  # Store the generated storyboard\n",
    "            \"embedding\": plot_embedding,  # Store the plot embedding\n",
    "            \"timestamp\": str(datetime.now())  # Add a timestamp for the entry\n",
    "        })\n",
    "        \n",
    "        # Save the updated knowledge base back to the file\n",
    "        with open(CONFIG[\"knowledge_base\"], \"w\") as f:\n",
    "            json.dump(kb, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Display an error if updating the knowledge base fails\n",
    "        display(Markdown(f\"âš ï¸ Could not update knowledge base: {e}\"))\n",
    "\n",
    "# Attach the methods to the StoryboardAgent class\n",
    "StoryboardAgent.retrieve_similar_plots = retrieve_similar_plots\n",
    "StoryboardAgent._update_knowledge_base = _update_knowledge_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Visualization Enhancements\n",
    "Professional visualizations with improved styling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T20:58:34.404781Z",
     "iopub.status.busy": "2025-04-09T20:58:34.404417Z",
     "iopub.status.idle": "2025-04-09T20:58:34.417484Z",
     "shell.execute_reply": "2025-04-09T20:58:34.416197Z",
     "shell.execute_reply.started": "2025-04-09T20:58:34.404755Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_mood(mood_counts: Dict):\n",
    "    \"\"\"Create an enhanced mood visualization, save it as an image, and display it\"\"\"\n",
    "    # Debug: Print the mood counts to ensure data is correct\n",
    "    print(f\"Debug: Mood counts received - {mood_counts}\")\n",
    "    \n",
    "    # Check if there is mood data to visualize\n",
    "    if not mood_counts:\n",
    "        display(Markdown(\"âš ï¸ No mood data available\"))\n",
    "        return\n",
    "\n",
    "    # Prepare data for visualization\n",
    "    moods = list(mood_counts.keys())  # List of moods\n",
    "    counts = list(mood_counts.values())  # List of counts for each mood\n",
    "\n",
    "    # Create a new figure for the plot\n",
    "    plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "    ax = plt.gca()  # Get the current axis\n",
    "\n",
    "    # Define a color mapping for moods to make the chart visually appealing\n",
    "    color_map = {\n",
    "        \"joyful\": \"#FFD700\", \"romantic\": \"#FF69B4\", \"tense\": \"#8B0000\",\n",
    "        \"suspenseful\": \"#4B0082\", \"dark\": \"#000000\", \"hopeful\": \"#32CD32\",\n",
    "        \"chaotic\": \"#FF4500\"\n",
    "    }\n",
    "\n",
    "    # Assign colors to each mood, defaulting to gray if not in the map\n",
    "    colors = [color_map.get(mood, \"#888888\") for mood in moods]\n",
    "\n",
    "    # Create a bar chart with the mood counts\n",
    "    bars = ax.bar(moods, counts, color=colors, edgecolor='white', linewidth=1)\n",
    "\n",
    "    # Style the chart\n",
    "    ax.set_title(\"Scene Mood Distribution\", fontsize=16, pad=20, fontweight='bold')  # Set the title\n",
    "    ax.set_xlabel(\"Mood Type\", fontsize=12)  # Set the x-axis label\n",
    "    ax.set_ylabel(\"Number of Scenes\", fontsize=12)  # Set the y-axis label\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)  # Add a light grid on the y-axis\n",
    "    ax.spines[['top', 'right']].set_visible(False)  # Remove top and right spines for cleaner look\n",
    "\n",
    "    # Add value labels on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()  # Get the height of the bar\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',  # Display the count\n",
    "                ha='center', va='bottom',  # Center horizontally, place above the bar\n",
    "                fontsize=11, fontweight='bold')  # Set font size and weight\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "\n",
    "    # Save the plot as an image file\n",
    "    chart_filename = \"mood_distribution.png\"\n",
    "    plt.savefig(chart_filename, bbox_inches='tight')\n",
    "    plt.close()  # Close the plot to prevent duplicate display\n",
    "\n",
    "    # Display the saved image using Markdown\n",
    "    display(Markdown(f\"![Mood Distribution Chart]({chart_filename})\"))\n",
    "\n",
    "def display_storyboard(storyboard: Dict):\n",
    "    \"\"\"Render the storyboard in plain Markdown format without HTML styling\"\"\"\n",
    "    # Display the storyboard title\n",
    "    display(Markdown(f\"## ðŸŽ¬ {storyboard.get('title', 'Untitled Storyboard')}\"))\n",
    "    \n",
    "    # Display each scene in a simple Markdown format\n",
    "    for scene in storyboard.get(\"scenes\", []):\n",
    "        mood = scene.get(\"mood\", \"neutral\").lower()\n",
    "        display(Markdown(f\"\"\"\n",
    "### ðŸŽ¥ Scene {scene.get('scene_number', 1)} ({mood.capitalize()})\n",
    "\n",
    "**Visual Description:**  \n",
    "{scene.get('description', 'No description available')}\n",
    "\n",
    "**Dialogue:**  \n",
    "\"{scene.get('dialogue', '...')}\"\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ–¥ï¸ Enhanced User Interface\n",
    "The UI now includes progress tracking and better visual feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T20:59:11.398444Z",
     "iopub.status.busy": "2025-04-09T20:59:11.397939Z",
     "iopub.status.idle": "2025-04-09T20:59:11.446233Z",
     "shell.execute_reply": "2025-04-09T20:59:11.444716Z",
     "shell.execute_reply.started": "2025-04-09T20:59:11.398390Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create enhanced input widgets for user interaction\n",
    "plot_input = widgets.Textarea(\n",
    "    placeholder='Describe your story (e.g., \"A detective discovers aliens in 1920s Chicago\")',  # Placeholder text for plot input\n",
    "    description='Plot:',  # Label for the plot input field\n",
    "    layout=Layout(width='80%', height='100px'),  # Set the size of the textarea\n",
    "    style={'description_width': 'initial'}  # Adjust the label width for better alignment\n",
    ")\n",
    "\n",
    "scenes_slider = widgets.IntSlider(\n",
    "    value=3,  # Default number of scenes\n",
    "    min=1,  # Minimum number of scenes\n",
    "    max=CONFIG[\"max_scenes\"],  # Maximum number of scenes (from CONFIG)\n",
    "    step=1,  # Increment step for the slider\n",
    "    description='Number of Scenes:',  # Label for the slider\n",
    "    continuous_update=False,  # Only update on release for better performance\n",
    "    style={'description_width': 'initial'}  # Adjust label width\n",
    ")\n",
    "\n",
    "style_selector = widgets.Dropdown(\n",
    "    options=['Cinematic', 'Documentary', 'Anime', 'Noir', 'Experimental'],  # Options for visual style\n",
    "    value='Cinematic',  # Default style\n",
    "    description='Visual Style:',  # Label for the dropdown\n",
    "    style={'description_width': 'initial'}  # Adjust label width\n",
    ")\n",
    "\n",
    "generate_btn = widgets.Button(\n",
    "    description='Generate Storyboard',  # Button text\n",
    "    button_style='success',  # Green button style\n",
    "    layout=Layout(width='200px', height='40px'),  # Set button size\n",
    "    icon='film'  # Add a film icon to the button\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()  # Create an output area for displaying results\n",
    "\n",
    "def on_generate_click(b):\n",
    "    \"\"\"Enhanced click handler with progress tracking for the generate button\"\"\"\n",
    "    with output_area:\n",
    "        # Clear the output area to start fresh\n",
    "        output_area.clear_output()\n",
    "\n",
    "        # Create a progress bar to show generation steps\n",
    "        steps = widgets.HBox([\n",
    "            widgets.Label(value=\"Progress:\"),  # Label for the progress bar\n",
    "            widgets.IntProgress(\n",
    "                value=0,  # Initial progress value\n",
    "                min=0,  # Minimum progress value\n",
    "                max=4,  # Maximum progress steps (4 steps)\n",
    "                description='',  # No description (label is enough)\n",
    "                bar_style='info'  # Blue progress bar style\n",
    "            )\n",
    "        ])\n",
    "        # Display the progress bar\n",
    "        display(steps)\n",
    "        \n",
    "        # Initialize the StoryboardAgent to handle generation tasks\n",
    "        agent = StoryboardAgent()\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Preparation - Update progress and show message\n",
    "            steps.children[1].value = 1\n",
    "            display(Markdown(\"### ðŸ” Analyzing your plot...\"))\n",
    "            \n",
    "            # Step 2: Generation - Generate the storyboard using the agent\n",
    "            steps.children[1].value = 2\n",
    "            display(Markdown(\"### ðŸŽ¥ Generating storyboard...\"))\n",
    "            storyboard = agent.execute_function(\n",
    "                \"generate_storyboard\",\n",
    "                plot=plot_input.value,  # Use the user-provided plot\n",
    "                num_scenes=scenes_slider.value  # Use the selected number of scenes\n",
    "            )\n",
    "            \n",
    "            # Check if the storyboard was generated successfully\n",
    "            if not storyboard:\n",
    "                raise ValueError(\"Generation failed\")\n",
    "            \n",
    "            # Step 3: Analysis - Analyze the mood distribution\n",
    "            steps.children[1].value = 3\n",
    "            display(Markdown(\"### ðŸ“Š Analyzing story structure...\"))\n",
    "            mood_analysis = agent.execute_function(\n",
    "                \"analyze_mood\",\n",
    "                storyboard=storyboard  # Pass the generated storyboard\n",
    "            )\n",
    "            \n",
    "            # Step 4: Display - Show the results\n",
    "            steps.children[1].value = 4\n",
    "            display(Markdown(f\"## ðŸŽ¬ {storyboard.get('title', 'Your Storyboard')}\"))\n",
    "            display_storyboard(storyboard)  # Display the formatted storyboard\n",
    "            visualize_mood(mood_analysis)  # Visualize the mood distribution\n",
    "            \n",
    "            # Save the storyboard to a file\n",
    "            filename = f\"storyboard_{plot_input.value[:20].replace(' ', '_')}.json\"\n",
    "            if agent.execute_function(\"save_storyboard\", storyboard=storyboard, filename=filename):\n",
    "                # Display a download button for the saved JSON file\n",
    "                display(Markdown(\"### ðŸ’¾ Download Options\"))\n",
    "                display(HTML(f\"\"\"\n",
    "                <a href=\"{filename}\" download>\n",
    "                    <button style=\"background-color:#4CAF50; color:white; padding:10px 20px; border:none; border-radius:6px; font-size:14px; margin:5px\">\n",
    "                        Download JSON\n",
    "                    </button>\n",
    "                </a>\n",
    "                \"\"\"))\n",
    "            \n",
    "            # Mark the progress as complete\n",
    "            steps.children[1].bar_style = 'success'\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If an error occurs, mark the progress as failed and show the error\n",
    "            steps.children[1].bar_style = 'danger'\n",
    "            display(Markdown(f\"## âŒ Error: {str(e)}\"))\n",
    "            display(Markdown(\"Please try again with a different plot description.\"))\n",
    "\n",
    "# Connect the click handler to the generate button\n",
    "generate_btn.on_click(on_generate_click)\n",
    "\n",
    "# Display the enhanced UI components\n",
    "display(Markdown(\"### âœï¸ Your Story Parameters\"))\n",
    "display(widgets.VBox([\n",
    "    plot_input,  # Plot input textarea\n",
    "    widgets.HBox([scenes_slider, style_selector]),  # Horizontal layout for slider and dropdown\n",
    "    generate_btn  # Generate button\n",
    "]))\n",
    "display(output_area)  # Output area for results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“– How to Use\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <table style=\"margin: 0 auto; border-collapse: collapse; width: 80%;\">\n",
    "        <tr style=\"background-color: #f2f2f2;\">\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">Step</th>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">Action</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">1</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Enter API Key - Get from Google AI Studio</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">2</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Describe Your Story - Be specific about setting and characters</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">3</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Adjust Parameters - Select scene count and visual style</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">4</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Generate - Create your storyboard</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">5</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Download - Save as JSON for further editing</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T20:39:27.128983Z",
     "iopub.status.busy": "2025-04-09T20:39:27.128546Z",
     "iopub.status.idle": "2025-04-09T20:39:27.138224Z",
     "shell.execute_reply": "2025-04-09T20:39:27.136595Z",
     "shell.execute_reply.started": "2025-04-09T20:39:27.128952Z"
    }
   },
   "source": [
    "## ðŸ› ï¸ Troubleshooting\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <table style=\"margin: 0 auto; border-collapse: collapse; width: 80%;\">\n",
    "        <tr style=\"background-color: #f2f2f2;\">\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">Issue</th>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">Solution</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">API Errors</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Check key validity and quota</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Empty Output</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Simplify plot description</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Format Issues</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Restart kernel and retry</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Slow Performance</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Reduce scene count</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Future Enhancements\n",
    "\n",
    "- Image generation integration\n",
    "- Collaborative editing\n",
    "- Script formatting options\n",
    "- Character development tools"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
